Metadata-Version: 2.4
Name: hapax
Version: 0.1.0
Summary: A flexible workflow system for LLM applications
Author-email: Teilo Millet <teilo@example.com>
License-Expression: MIT
License-File: LICENSE
Keywords: llm,opentelemetry,pipeline,workflow
Classifier: Development Status :: 4 - Beta
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.9
Requires-Dist: langchain>=0.3.0
Requires-Dist: loguru>=0.7.0
Requires-Dist: networkx>=3.0
Requires-Dist: opentelemetry-api>=1.21.0
Requires-Dist: opentelemetry-instrumentation>=0.42b0
Requires-Dist: opentelemetry-sdk>=1.21.0
Requires-Dist: opentelemetry-semantic-conventions>=0.42b0
Provides-Extra: dev
Requires-Dist: black>=23.0.0; extra == 'dev'
Requires-Dist: isort>=5.0.0; extra == 'dev'
Requires-Dist: mypy>=1.0.0; extra == 'dev'
Provides-Extra: llm
Requires-Dist: torch>=2.2.0; extra == 'llm'
Requires-Dist: transformers>=4.38.1; extra == 'llm'
Provides-Extra: test
Requires-Dist: pytest-asyncio>=0.21.0; extra == 'test'
Requires-Dist: pytest-cov>=4.0.0; extra == 'test'
Requires-Dist: pytest>=7.0; extra == 'test'
Description-Content-Type: text/markdown

# Hapax

A flexible workflow system for LLM applications with built-in observability.

## Features

- Simple, intuitive workflow creation
- Built-in OpenTelemetry tracing
- Type-safe workflow validation
- Parallel and conditional execution
- LangChain integration

## Installation

```bash
pip install hapax
```

## Quick Start

```python
from hapax.workflow import Workflow

# Create a simple workflow
workflow = (
    Workflow()
    .add(load_document)
    .add(split_text)
    .add(create_embeddings)
    .add(search_relevant)
    .add(generate_answer)
)

# Run with tracing
result = await workflow.run(
    input={"document": doc, "question": "What is...?"},
    trace=True
)
```

## RAG with Observability Example

The `examples/rag_with_observability.py` demonstrates how to build a Retrieval-Augmented Generation (RAG) pipeline with built-in observability using Hapax. This example showcases:

- Processing both text and tabular data
- Using LangChain's MultiVectorRetriever for improved retrieval
- Adding observability using the `@obs` decorator
- Error handling and state management
- Type-safe workflow validation

To run the example:

1. Install required dependencies:
```bash
pip install -r requirements.txt
```

2. Set your OpenAI API key:
```bash
export OPENAI_API_KEY=your-api-key
```

3. Run the test script:
```bash
python examples/test_rag_pipeline.py
```

The example will demonstrate:
- Loading and processing semi-structured data (text and tables)
- Generating summaries for improved retrieval
- Answering questions using both context types
- Observability metrics and tracing throughout the pipeline

## Development

1. Clone the repository:
```bash
git clone https://github.com/teilomillet/hapax-py.git
cd hapax-py
```

2. Create a virtual environment and install dependencies:
```bash
python -m venv .venv
source .venv/bin/activate
pip install -e ".[dev,test]"
```

3. Run tests:
```bash
pytest tests/ -v
```

## License

MIT License