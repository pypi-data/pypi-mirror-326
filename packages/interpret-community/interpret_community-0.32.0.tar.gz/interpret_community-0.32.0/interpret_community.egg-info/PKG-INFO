Metadata-Version: 2.2
Name: interpret_community
Version: 0.32.0
Summary: Microsoft Interpret Extensions SDK for Python
Home-page: https://github.com/interpretml/interpret-community
Author: Microsoft Corp
Author-email: ilmat@microsoft.com
License: MIT License
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Operating System :: Microsoft :: Windows
Classifier: Operating System :: MacOS
Classifier: Operating System :: POSIX :: Linux
Description-Content-Type: text/markdown
License-File: LICENSE.txt
Requires-Dist: numpy
Requires-Dist: pandas
Requires-Dist: scipy
Requires-Dist: ml-wrappers~=0.6.0
Requires-Dist: scikit-learn
Requires-Dist: packaging
Requires-Dist: interpret-core<=0.6.9,>=0.1.20
Requires-Dist: shap<=0.46.0,>=0.20.0
Requires-Dist: raiutils~=0.4.0
Provides-Extra: sample
Requires-Dist: hdbscan; extra == "sample"
Provides-Extra: deep
Requires-Dist: tensorflow; extra == "deep"
Requires-Dist: pyyaml; extra == "deep"
Requires-Dist: keras; extra == "deep"
Provides-Extra: mimic
Requires-Dist: lightgbm; extra == "mimic"
Provides-Extra: lime
Requires-Dist: lime>=0.2.0.0; extra == "lime"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: summary

# Microsoft Interpret Community SDK for Python

### This package has been tested with Python 3.7, 3.8 and 3.9

The Interpret Community SDK builds on Interpret, an open source python package from Microsoft Research for training interpretable models, and helps to explain blackbox systems by adding additional extensions from the community to interpret ML models.

Interpret-Community is an experimental repository that hosts a wide range of community developed machine learning interpretability techniques. This repository makes it easy for anyone involved in the development of a machine learning system to improve transparency around their machine learning models. Data scientists, machine learning engineers, and researchers can easily add their own interpretability techniques via the set of extension hooks built into the peer repository, Interpret, and expand this repository to include their custom-made interpretability techniques.

Highlights of the package include:

- The TabularExplainer can be used to give local and global feature importances
- The best explainer is automatically chosen for the user based on the model
- Local feature importances are for each evaluation row
- Global feature importances summarize the most importance features at the model-level
- The API supports both dense (numpy or pandas) and sparse (scipy) datasets
- There are utilities provided to convert engineered explanations, based on preprocessed data before training a model, to raw explanations on the original dataset
- For more advanced users, individual explainers can be used
- The KernelExplainer, GPUKernelExplainer, PFIExplainer and MimicExplainer are for BlackBox models
- The MimicExplainer is faster but less accurate than the KernelExplainer, and supports various surrogate model types
- The TreeExplainer is for tree-based models
- The LinearExplainer is for linear models
- The DeepExplainer is for DNN tensorflow or pytorch models
- The PFIExplainer can quickly compute global importance values
- LIMEExplainer builds local linear approximations of the model's behavior by perturbing each instance
- GPUKernelExplainer is GPU-accelerated implementation of SHAP's KernelExplainer as a part of RAPIDS's cuML library, and is optimized for GPU models, like those in cuML. It can be used with CPU-based estimators too.
- An adapter to convert any feature importance values to an interpret-community style explanation

Please see the github website for the documentation and sample notebooks:
https://github.com/interpretml/interpret-community

Auto-generated sphinx API documentation can be found here:
https://interpret-community.readthedocs.io/en/latest/index.html

More information on the ExplanationDashboard can be found here:
https://github.com/microsoft/responsible-ai-toolbox
